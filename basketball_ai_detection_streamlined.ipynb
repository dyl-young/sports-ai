{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBJiIfXk5MVJ"
      },
      "source": [
        "# Basketball AI: Streamlined Player Detection and Tracking\n",
        "\n",
        "This notebook takes a video and team configuration as input and outputs annotated video with player detection, tracking, and identification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkoCconK5MVK"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "Set your API keys, source video path, and team rosters here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hb702YQ95MVK",
        "outputId": "4aa309d2-b439-4a7d-e378-36918238e082",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOME: /content\n",
            "Source video: /content/your_video.mp4\n",
            "Output video: /content/output_annotated.mp4\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Set your API keys\n",
        "os.environ[\"HF_TOKEN\"] = \"YOUR_HF_TOKEN_HERE\"\n",
        "os.environ[\"ROBOFLOW_API_KEY\"] = \"YOUR_ROBOFLOW_API_KEY_HERE\"\n",
        "\n",
        "# Configure paths\n",
        "HOME = Path.cwd()\n",
        "SOURCE_VIDEO_PATH = HOME / \"your_video.mp4\"  # Change this to your video path\n",
        "OUTPUT_VIDEO_PATH = HOME / \"output_annotated.mp4\"\n",
        "\n",
        "# Configure team rosters\n",
        "TEAM_ROSTERS = {\n",
        "    \"New York Knicks\": {\n",
        "        \"55\": \"Hukporti\",\n",
        "        \"1\": \"Payne\",\n",
        "        \"0\": \"Wright\",\n",
        "        \"11\": \"Brunson\",\n",
        "        \"3\": \"Hart\",\n",
        "        \"32\": \"Towns\",\n",
        "        \"44\": \"Shamet\",\n",
        "        \"25\": \"Bridges\",\n",
        "        \"2\": \"McBride\",\n",
        "        \"23\": \"Robinson\",\n",
        "        \"8\": \"Anunoby\",\n",
        "        \"4\": \"Dadiet\",\n",
        "        \"5\": \"Achiuwa\",\n",
        "        \"13\": \"Kolek\"\n",
        "    },\n",
        "        \"Boston Celtics\": {\n",
        "        \"42\": \"Horford\",\n",
        "        \"55\": \"Scheierman\",\n",
        "        \"9\": \"White\",\n",
        "        \"20\": \"Davison\",\n",
        "        \"7\": \"Brown\",\n",
        "        \"0\": \"Tatum\",\n",
        "        \"27\": \"Walsh\",\n",
        "        \"4\": \"Holiday\",\n",
        "        \"8\": \"Porzingis\",\n",
        "        \"40\": \"Kornet\",\n",
        "        \"88\": \"Queta\",\n",
        "        \"11\": \"Pritchard\",\n",
        "        \"30\": \"Hauser\",\n",
        "        \"12\": \"Craig\",\n",
        "        \"26\": \"Tillman\"\n",
        "    }\n",
        "}\n",
        "\n",
        "TEAM_COLORS = {\n",
        "    \"New York Knicks\": \"#006BB6\",\n",
        "    \"Boston Celtics\": \"#007A33\"\n",
        "}\n",
        "\n",
        "# Set which team is which cluster (you may need to adjust after first run)\n",
        "TEAM_NAMES = {\n",
        "    0: \"Boston Celtics\",\n",
        "    1: \"New York Knicks\",\n",
        "}\n",
        "\n",
        "print(\"HOME:\", HOME)\n",
        "print(\"Source video:\", SOURCE_VIDEO_PATH)\n",
        "print(\"Output video:\", OUTPUT_VIDEO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72Os158C5MVK"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqxy-TyW5MVL"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuGijS-25MVL"
      },
      "outputs": [],
      "source": [
        "# Install SAM2 real-time\n",
        "!git clone https://github.com/Gy920/segment-anything-2-real-time.git\n",
        "%cd {HOME}/segment-anything-2-real-time\n",
        "!pip install -e . -q\n",
        "!python setup.py build_ext --inplace\n",
        "!(cd checkpoints && bash download_ckpts.sh)\n",
        "%cd {HOME}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peS8cQ0N5MVL"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q gdown\n",
        "!pip install -q inference-gpu\n",
        "!pip install -q git+https://github.com/roboflow/supervision.git\n",
        "!pip install -q git+https://github.com/roboflow/sports.git@feat/basketball\n",
        "!pip install -q transformers num2words\n",
        "!pip install -q flash-attn --no-build-isolation\n",
        "\n",
        "os.environ[\"ONNXRUNTIME_EXECUTION_PROVIDERS\"] = \"[CUDAExecutionProvider]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycPv_p2Z5MVL"
      },
      "outputs": [],
      "source": [
        "# Download fonts for annotations\n",
        "!gdown https://drive.google.com/drive/folders/1RBjpI5Xleb58lujeusxH0W5zYMMA4ytO -O {HOME / \"fonts\"} --folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxGY8wKY5MVL"
      },
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7uz1yHD5MVL"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Video\n",
        "from typing import Dict, List, Optional, Union, Iterable, Tuple\n",
        "from operator import itemgetter\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "import supervision as sv\n",
        "from inference import get_model\n",
        "from sports.common.team import TeamClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEpQTn2m5MVL"
      },
      "source": [
        "## Load Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZZ6iGkA5MVM"
      },
      "outputs": [],
      "source": [
        "# Load detection model\n",
        "PLAYER_DETECTION_MODEL_ID = \"basketball-player-detection-3-ycjdo/4\"\n",
        "PLAYER_DETECTION_MODEL_CONFIDENCE = 0.4\n",
        "PLAYER_DETECTION_MODEL_IOU_THRESHOLD = 0.9\n",
        "PLAYER_DETECTION_MODEL = get_model(model_id=PLAYER_DETECTION_MODEL_ID)\n",
        "\n",
        "PLAYER_CLASS_IDS = [3, 4, 5, 6, 7]  # player classes\n",
        "NUMBER_CLASS_ID = 2\n",
        "\n",
        "# Load number recognition model\n",
        "NUMBER_RECOGNITION_MODEL_ID = \"basketball-jersey-numbers-ocr/3\"\n",
        "NUMBER_RECOGNITION_MODEL = get_model(model_id=NUMBER_RECOGNITION_MODEL_ID)\n",
        "NUMBER_RECOGNITION_MODEL_PROMPT = \"Read the number.\"\n",
        "\n",
        "# Load SAM2 tracking model\n",
        "%cd {HOME}/segment-anything-2-real-time\n",
        "from sam2.build_sam import build_sam2_camera_predictor\n",
        "\n",
        "SAM2_CHECKPOINT = \"checkpoints/sam2.1_hiera_large.pt\"\n",
        "SAM2_CONFIG = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
        "predictor = build_sam2_camera_predictor(SAM2_CONFIG, SAM2_CHECKPOINT)\n",
        "%cd {HOME}\n",
        "\n",
        "print(\"All models loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOwPUzrK5MVM"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzEuy9SD5MVM"
      },
      "outputs": [],
      "source": [
        "def filter_segments_by_distance(mask: np.ndarray, distance_threshold: float = 300) -> np.ndarray:\n",
        "    \"\"\"Keeps the main segment and removes segments farther than distance_threshold.\"\"\"\n",
        "    assert mask.dtype == bool, \"Input mask must be boolean.\"\n",
        "    mask_uint8 = mask.astype(np.uint8)\n",
        "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_uint8, connectivity=8)\n",
        "    if num_labels <= 1:\n",
        "        return mask.copy()\n",
        "    main_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
        "    main_centroid = centroids[main_label]\n",
        "    filtered_mask = np.zeros_like(mask, dtype=bool)\n",
        "    for label in range(1, num_labels):\n",
        "        centroid = centroids[label]\n",
        "        dist = np.linalg.norm(centroid - main_centroid)\n",
        "        if label == main_label or dist <= distance_threshold:\n",
        "            filtered_mask[labels == label] = True\n",
        "    return filtered_mask\n",
        "\n",
        "\n",
        "def shrink_boxes(xyxy: np.ndarray, scale: float) -> np.ndarray:\n",
        "    \"\"\"Shrinks bounding boxes by a given scale factor while keeping their centers fixed.\"\"\"\n",
        "    x1, y1, x2, y2 = xyxy[:, 0], xyxy[:, 1], xyxy[:, 2], xyxy[:, 3]\n",
        "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "    w, h = (x2 - x1) * scale, (y2 - y1) * scale\n",
        "    new_x1, new_y1 = cx - w / 2, cy - h / 2\n",
        "    new_x2, new_y2 = cx + w / 2, cy + h / 2\n",
        "    return np.stack([new_x1, new_y1, new_x2, new_y2], axis=1)\n",
        "\n",
        "\n",
        "def xyxy_to_mask(boxes: np.ndarray, resolution_wh: Tuple[int, int]) -> np.ndarray:\n",
        "    \"\"\"Converts bounding boxes into bool masks.\"\"\"\n",
        "    width, height = resolution_wh\n",
        "    n = boxes.shape[0]\n",
        "    masks = np.zeros((n, height, width), dtype=bool)\n",
        "    for i, (x_min, y_min, x_max, y_max) in enumerate(boxes):\n",
        "        x_min = max(0, int(x_min))\n",
        "        y_min = max(0, int(y_min))\n",
        "        x_max = min(width - 1, int(x_max))\n",
        "        y_max = min(height - 1, int(y_max))\n",
        "        if x_max >= x_min and y_max >= y_min:\n",
        "            masks[i, y_min:y_max + 1, x_min:x_max + 1] = True\n",
        "    return masks\n",
        "\n",
        "\n",
        "def coords_above_threshold(matrix: np.ndarray, threshold: float, sort_desc: bool = True) -> List[Tuple[int, int]]:\n",
        "    \"\"\"Return all (row_index, col_index) where value > threshold.\"\"\"\n",
        "    A = np.asarray(matrix)\n",
        "    rows, cols = np.where(A > threshold)\n",
        "    pairs = list(zip(rows.tolist(), cols.tolist()))\n",
        "    if sort_desc:\n",
        "        pairs.sort(key=lambda rc: A[rc[0], rc[1]], reverse=True)\n",
        "    return pairs\n",
        "\n",
        "\n",
        "Value = Union[int, str, None]\n",
        "\n",
        "class PropertyValidator:\n",
        "    \"\"\"Validate a property per tracker_id after N consecutive identical reports.\"\"\"\n",
        "\n",
        "    def __init__(self, n_consecutive: int):\n",
        "        if n_consecutive < 1:\n",
        "            raise ValueError(\"n_consecutive must be >= 1\")\n",
        "        self.n = n_consecutive\n",
        "        self._streak: Dict[int, int] = {}\n",
        "        self._last: Dict[int, Optional[str]] = {}\n",
        "        self._validated: Dict[int, Optional[str]] = {}\n",
        "\n",
        "    def reset_id(self, tracker_id: int) -> None:\n",
        "        self._streak.pop(tracker_id, None)\n",
        "        self._last.pop(tracker_id, None)\n",
        "        self._validated.pop(tracker_id, None)\n",
        "\n",
        "    def reset_all(self) -> None:\n",
        "        self._streak.clear()\n",
        "        self._last.clear()\n",
        "        self._validated.clear()\n",
        "\n",
        "    def _normalize(self, value: Value) -> Optional[str]:\n",
        "        if value is None:\n",
        "            return None\n",
        "        s = str(value).strip()\n",
        "        return s if s else None\n",
        "\n",
        "    def update(self, tracker_ids: List[int], values: List[Value]) -> List[Optional[str]]:\n",
        "        if len(tracker_ids) != len(values):\n",
        "            raise ValueError(\"tracker_ids and values must have the same length\")\n",
        "        output: List[Optional[str]] = []\n",
        "        for tid, raw in zip(tracker_ids, values):\n",
        "            if tid in self._validated and self._validated[tid] is not None:\n",
        "                output.append(self._validated[tid])\n",
        "                continue\n",
        "            val = self._normalize(raw)\n",
        "            if val is None:\n",
        "                output.append(None)\n",
        "                self._streak.setdefault(tid, 0)\n",
        "                self._last.setdefault(tid, None)\n",
        "                self._validated.setdefault(tid, None)\n",
        "                continue\n",
        "            last = self._last.get(tid)\n",
        "            if last == val:\n",
        "                self._streak[tid] = self._streak.get(tid, 0) + 1\n",
        "            else:\n",
        "                self._streak[tid] = 1\n",
        "                self._last[tid] = val\n",
        "            if self._streak[tid] >= self.n:\n",
        "                self._validated[tid] = self._last[tid]\n",
        "            output.append(self._validated.get(tid))\n",
        "            self._last.setdefault(tid, val)\n",
        "            self._validated.setdefault(tid, None)\n",
        "        return output\n",
        "\n",
        "    def get_validated(self, tracker_ids: Union[int, Iterable[int]]) -> Union[Optional[str], List[Optional[str]]]:\n",
        "        \"\"\"Query validated properties for one or many tracker_ids.\"\"\"\n",
        "        if isinstance(tracker_ids, int):\n",
        "            return self._validated.get(tracker_ids)\n",
        "        return [self._validated.get(tid) for tid in tracker_ids]\n",
        "\n",
        "    def validated_dict(self) -> Dict[int, str]:\n",
        "        \"\"\"Snapshot of validated assignments. Excludes None values.\"\"\"\n",
        "        return {tid: val for tid, val in self._validated.items() if val is not None}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWa8o40o5MVM"
      },
      "source": [
        "## Train Team Classifier\n",
        "\n",
        "Collect player crops from the video and train a classifier to distinguish between teams."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgTXlsGF5MVM"
      },
      "outputs": [],
      "source": [
        "print(\"Collecting training samples for team classification...\")\n",
        "STRIDE = 30\n",
        "crops = []\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(source_path=SOURCE_VIDEO_PATH, stride=STRIDE)\n",
        "\n",
        "for frame in tqdm(frame_generator, desc=\"Extracting player crops\"):\n",
        "    result = PLAYER_DETECTION_MODEL.infer(\n",
        "        frame,\n",
        "        confidence=PLAYER_DETECTION_MODEL_CONFIDENCE,\n",
        "        iou_threshold=PLAYER_DETECTION_MODEL_IOU_THRESHOLD,\n",
        "        class_agnostic_nms=True\n",
        "    )[0]\n",
        "    detections = sv.Detections.from_inference(result)\n",
        "    detections = detections[np.isin(detections.class_id, PLAYER_CLASS_IDS)]\n",
        "\n",
        "    boxes = shrink_boxes(xyxy=detections.xyxy, scale=0.4)\n",
        "    for box in boxes:\n",
        "        crops.append(sv.crop_image(frame, box))\n",
        "\n",
        "print(f\"Collected {len(crops)} player crops\")\n",
        "\n",
        "# Train team classifier\n",
        "print(\"Training team classifier...\")\n",
        "team_classifier = TeamClassifier(device=\"cuda\")\n",
        "team_classifier.fit(crops)\n",
        "print(\"Team classifier trained successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc7d-RsL5MVM"
      },
      "source": [
        "## Process Video\n",
        "\n",
        "This is the main processing loop that:\n",
        "1. Detects players in the first frame\n",
        "2. Tracks them throughout the video using SAM2\n",
        "3. Classifies them into teams\n",
        "4. Recognizes jersey numbers\n",
        "5. Creates annotated output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErHycUIm5MVM"
      },
      "outputs": [],
      "source": [
        "print(\"Starting video processing...\")\n",
        "\n",
        "# Initialize validators\n",
        "number_validator = PropertyValidator(n_consecutive=3)\n",
        "team_validator = PropertyValidator(n_consecutive=1)\n",
        "\n",
        "# Storage for frames and detections\n",
        "frames_history = []\n",
        "detections_history = []\n",
        "\n",
        "# Get first frame and initialize tracking\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "print(\"Detecting players in first frame...\")\n",
        "result = PLAYER_DETECTION_MODEL.infer(\n",
        "    frame,\n",
        "    confidence=PLAYER_DETECTION_MODEL_CONFIDENCE,\n",
        "    iou_threshold=PLAYER_DETECTION_MODEL_IOU_THRESHOLD,\n",
        "    class_agnostic_nms=True\n",
        ")[0]\n",
        "detections = sv.Detections.from_inference(result)\n",
        "detections = detections[np.isin(detections.class_id, PLAYER_CLASS_IDS)]\n",
        "\n",
        "# Assign tracker IDs\n",
        "TRACKER_ID = list(range(1, len(detections.class_id) + 1))\n",
        "\n",
        "# Classify teams\n",
        "boxes = shrink_boxes(xyxy=detections.xyxy, scale=0.4)\n",
        "crops = [sv.crop_image(frame, box) for box in boxes]\n",
        "TEAMS = np.array(team_classifier.predict(crops))\n",
        "team_validator.update(tracker_ids=TRACKER_ID, values=TEAMS)\n",
        "\n",
        "# Initialize SAM2 tracking\n",
        "print(\"Initializing SAM2 tracking...\")\n",
        "with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
        "    predictor.load_first_frame(frame)\n",
        "    for xyxy, tracker_id in zip(detections.xyxy, TRACKER_ID):\n",
        "        xyxy = np.array([xyxy])\n",
        "        _, object_ids, mask_logits = predictor.add_new_prompt(\n",
        "            frame_idx=0,\n",
        "            obj_id=tracker_id,\n",
        "            bbox=xyxy\n",
        "        )\n",
        "\n",
        "# Process all frames\n",
        "print(\"Processing video frames...\")\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "for index, frame in tqdm(enumerate(frame_generator), desc=\"Processing frames\"):\n",
        "    frame_h, frame_w, *_ = frame.shape\n",
        "\n",
        "    with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
        "        tracker_ids, mask_logits = predictor.track(frame)\n",
        "        tracker_ids = np.array(tracker_ids)\n",
        "        masks = (mask_logits > 0.0).cpu().numpy()\n",
        "        masks = np.squeeze(masks).astype(bool)\n",
        "\n",
        "        player_masks = np.array([\n",
        "            filter_segments_by_distance(mask, distance_threshold=300)\n",
        "            for mask in masks\n",
        "        ])\n",
        "\n",
        "        player_detections = sv.Detections(\n",
        "            xyxy=sv.mask_to_xyxy(masks=player_masks),\n",
        "            mask=player_masks,\n",
        "            tracker_id=tracker_ids\n",
        "        )\n",
        "\n",
        "        frames_history.append(frame)\n",
        "        detections_history.append(player_detections)\n",
        "\n",
        "        # Perform number recognition at intervals\n",
        "        if index % 5 == 0:\n",
        "            result = PLAYER_DETECTION_MODEL.infer(\n",
        "                frame,\n",
        "                confidence=PLAYER_DETECTION_MODEL_CONFIDENCE,\n",
        "                iou_threshold=PLAYER_DETECTION_MODEL_IOU_THRESHOLD\n",
        "            )[0]\n",
        "            number_detections = sv.Detections.from_inference(result)\n",
        "            number_detections = number_detections[number_detections.class_id == NUMBER_CLASS_ID]\n",
        "\n",
        "            if len(number_detections) > 0:\n",
        "                number_detections.mask = xyxy_to_mask(\n",
        "                    boxes=number_detections.xyxy,\n",
        "                    resolution_wh=(frame_w, frame_h)\n",
        "                )\n",
        "\n",
        "                # Recognize numbers\n",
        "                number_crops = [\n",
        "                    sv.crop_image(frame, xyxy)\n",
        "                    for xyxy in sv.pad_boxes(xyxy=number_detections.xyxy, px=10, py=10)\n",
        "                ]\n",
        "                numbers = [\n",
        "                    NUMBER_RECOGNITION_MODEL.predict(number_crop, NUMBER_RECOGNITION_MODEL_PROMPT)[0]\n",
        "                    for number_crop in number_crops\n",
        "                ]\n",
        "\n",
        "                # Match numbers to players\n",
        "                iou = sv.mask_iou_batch(\n",
        "                    masks_true=player_masks,\n",
        "                    masks_detection=number_detections.mask,\n",
        "                    overlap_metric=sv.OverlapMetric.IOS\n",
        "                )\n",
        "\n",
        "                pairs = coords_above_threshold(iou, 0.9)\n",
        "                if pairs:\n",
        "                    player_idx, number_idx = zip(*pairs)\n",
        "                    player_idx = [i + 1 for i in player_idx]\n",
        "                    numbers = list(itemgetter(*number_idx)(numbers))\n",
        "                    number_validator.update(tracker_ids=player_idx, values=numbers)\n",
        "\n",
        "print(f\"Processed {len(frames_history)} frames\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WorMP1QK5MVM"
      },
      "source": [
        "## Generate Annotated Output Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeHBpBTK5MVM"
      },
      "outputs": [],
      "source": [
        "print(\"Generating annotated video...\")\n",
        "\n",
        "TEMP_OUTPUT_PATH = HOME / \"temp_output.mp4\"\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# Setup annotators\n",
        "team_colors = sv.ColorPalette.from_hex([\n",
        "    TEAM_COLORS[TEAM_NAMES[0]],\n",
        "    TEAM_COLORS[TEAM_NAMES[1]]\n",
        "])\n",
        "\n",
        "team_mask_annotator = sv.MaskAnnotator(\n",
        "    color=team_colors,\n",
        "    opacity=0.5,\n",
        "    color_lookup=sv.ColorLookup.INDEX\n",
        ")\n",
        "\n",
        "team_label_annotator = sv.RichLabelAnnotator(\n",
        "    font_path=f\"{HOME}/fonts/Staatliches-Regular.ttf\",\n",
        "    font_size=40,\n",
        "    color=team_colors,\n",
        "    text_color=sv.Color.WHITE,\n",
        "    text_position=sv.Position.BOTTOM_CENTER,\n",
        "    text_offset=(0, 10),\n",
        "    color_lookup=sv.ColorLookup.INDEX\n",
        ")\n",
        "\n",
        "# Write annotated video\n",
        "with sv.VideoSink(str(TEMP_OUTPUT_PATH), video_info) as sink:\n",
        "    for frame, detections in tqdm(zip(frames_history, detections_history), desc=\"Annotating frames\", total=len(frames_history)):\n",
        "        detections = detections[detections.area > 100]\n",
        "\n",
        "        teams = team_validator.get_validated(tracker_ids=detections.tracker_id)\n",
        "        teams = np.array(teams).astype(int)\n",
        "        numbers = number_validator.get_validated(tracker_ids=detections.tracker_id)\n",
        "        numbers = np.array(numbers)\n",
        "\n",
        "        labels = [\n",
        "            f\"#{number} {TEAM_ROSTERS[TEAM_NAMES[team]].get(number, '')}\"\n",
        "            for number, team in zip(numbers, teams)\n",
        "        ]\n",
        "\n",
        "        annotated_frame = frame.copy()\n",
        "        annotated_frame = team_mask_annotator.annotate(\n",
        "            scene=annotated_frame,\n",
        "            detections=detections,\n",
        "            custom_color_lookup=teams\n",
        "        )\n",
        "        annotated_frame = team_label_annotator.annotate(\n",
        "            scene=annotated_frame,\n",
        "            detections=detections,\n",
        "            labels=labels,\n",
        "            custom_color_lookup=teams\n",
        "        )\n",
        "\n",
        "        sink.write_frame(annotated_frame)\n",
        "\n",
        "# Compress output\n",
        "print(\"Compressing output video...\")\n",
        "!ffmpeg -y -loglevel error -i {TEMP_OUTPUT_PATH} -vcodec libx264 -crf 28 {OUTPUT_VIDEO_PATH}\n",
        "\n",
        "# Clean up temp file\n",
        "import os\n",
        "if os.path.exists(TEMP_OUTPUT_PATH):\n",
        "    os.remove(TEMP_OUTPUT_PATH)\n",
        "\n",
        "print(f\"\\nProcessing complete! Output saved to: {OUTPUT_VIDEO_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPBf9qkz5MVM"
      },
      "source": [
        "## Display Output Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIZAQZ2F5MVM"
      },
      "outputs": [],
      "source": [
        "Video(OUTPUT_VIDEO_PATH, embed=True, width=1080)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}